import streamlit as st
import cv2
import numpy as np
import pandas as pd
from scipy.signal import savgol_filter
import tempfile
import matplotlib.pyplot as plt
import io

# --- åŸºæœ¬è¨­å®š ---
plt.switch_backend('Agg')
plt.rcParams['mathtext.fontset'] = 'cm'
RADIUS_M = 0.016
VERSION = "3.2.0_MatteColor_Debug" 
MAX_ANALYSIS_WIDTH = 1280

def create_graph_image(df_sub, x_col, y_col, x_label, y_label, x_unit, y_unit, color, size, x_max, y_min, y_max, shade_range=None, markers=None):
    fig, ax = plt.subplots(figsize=(size/100, size/100), dpi=100)
    try:
        if not df_sub.empty:
            ax.plot(df_sub[x_col], df_sub[y_col], color=color, linewidth=2, alpha=0.8)
            ax.scatter(df_sub[x_col].iloc[-1], df_sub[y_col].iloc[-1], color=color, s=60, edgecolors='white', zorder=5)
            
            if markers is not None:
                for t_val in markers:
                    m_row = df_sub.iloc[(df_sub['t']-t_val).abs().argsort()[:1]]
                    if not m_row.empty:
                        ax.scatter(m_row[x_col], m_row[y_col], color='orange', s=50, marker='o', edgecolors='black', zorder=10)

            if shade_range is not None and y_col == 'F':
                t_s, t_e = shade_range
                mask = (df_sub['t'] >= t_s) & (df_sub['t'] <= t_e)
                ax.fill_between(df_sub[x_col], df_sub[y_col], where=mask, color=color, alpha=0.3)
        
        ax.set_title(f"${y_label}$ - ${x_label}$", fontsize=14, fontweight='bold')
        ax.set_xlabel(f"${x_label}$ [{x_unit}]", fontsize=11)
        ax.set_ylabel(f"${y_label}$ [{y_unit}]", fontsize=11)
        ax.set_xlim(0, max(float(x_max), 0.1))
        yr = max(float(y_max - y_min), 0.01)
        ax.set_ylim(y_min - yr*0.1, y_max + yr*0.1)
        ax.grid(True, linestyle='--', alpha=0.5)
    except: pass
    plt.tight_layout()
    buf = io.BytesIO()
    fig.savefig(buf, format="png")
    buf.seek(0)
    img = cv2.imdecode(np.frombuffer(buf.getvalue(), dtype=np.uint8), 1)
    plt.close(fig)
    return cv2.resize(img, (size, size)) if img is not None else np.zeros((size, size, 3), dtype=np.uint8)

def format_sci_latex(val):
    try:
        if abs(val) < 1e-6 and val != 0: return "0"
        s = f"{val:.2e}"
        base, exp = s.split('e')
        exp_int = int(exp)
        if exp_int == 0: return f"{float(base):.2f}"
        return rf"{base} \times 10^{{{exp_int}}}"
    except: return "0"

st.set_page_config(page_title=f"CartGrapher Studio v{VERSION}", layout="wide")
st.title(f"ğŸš€ CartGrapher Studio ver {VERSION}")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("è§£æè¨­å®š")
mass_input = st.sidebar.number_input("å°è»Šã®è³ªé‡ $m$ [kg]", value=0.100, min_value=0.001, format="%.3f", step=0.001)

st.sidebar.markdown("---")
st.sidebar.subheader("è‰²èªè­˜ã®èª¿æ•´ (HSV)")
st.sidebar.info("èªè­˜ãŒã†ã¾ãã„ã‹ãªã„å ´åˆã€ã“ã“ã®æ•°å€¤ã‚’å¤‰æ›´ã—ã¦ã€Œãƒã‚¹ã‚¯ç¢ºèªã€ã‚¿ãƒ–ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# è‰²èª¿æ•´ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
# ãƒ”ãƒ³ã‚¯ (è–„ã„ãƒ”ãƒ³ã‚¯å¯¾å¿œ: å½©åº¦Sã‚’ä½ãè¨­å®š)
st.sidebar.markdown("**ãƒ”ãƒ³ã‚¯ãƒãƒ¼ã‚«ãƒ¼ (å¤–å´)**")
p_h_min = st.sidebar.slider("Pink Hue Min", 0, 180, 140)
p_h_max = st.sidebar.slider("Pink Hue Max", 0, 180, 180)
p_s_min = st.sidebar.slider("Pink Sat Min (å½©åº¦)", 0, 255, 30) # ãƒ‘ã‚¹ãƒ†ãƒ«å¯¾å¿œã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¸‹ã’
p_v_min = st.sidebar.slider("Pink Val Min (æ˜åº¦)", 0, 255, 100)

# ç·‘ (æš—ã„ç·‘å¯¾å¿œ)
st.sidebar.markdown("**ç·‘ãƒãƒ¼ã‚«ãƒ¼ (ä¸­å¿ƒ)**")
g_h_min = st.sidebar.slider("Green Hue Min", 0, 180, 35)
g_h_max = st.sidebar.slider("Green Hue Max", 0, 180, 95)
g_s_min = st.sidebar.slider("Green Sat Min", 0, 255, 40)
g_v_min = st.sidebar.slider("Green Val Min", 0, 255, 50)

# ç™½ãƒ›ã‚¤ãƒ¼ãƒ«
st.sidebar.markdown("**ç™½ãƒ›ã‚¤ãƒ¼ãƒ« (å…¨ä½“)**")
w_s_max = st.sidebar.slider("White Sat Max (å½©åº¦ä¸Šé™)", 0, 255, 60) # ç™½ã¯å½©åº¦ãŒä½ã„
w_v_min = st.sidebar.slider("White Val Min (æ˜åº¦ä¸‹é™)", 0, 255, 80) # æš—ã„ç™½ã‚‚æ‹¾ã†

uploaded_file = st.file_uploader("å‹•ç”»ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (MP4/MOV)", type=["mp4", "mov"])

if uploaded_file:
    tfile_temp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
    tfile_temp.write(uploaded_file.read())
    tfile_temp.close()

    # ã‚¿ãƒ–ã‚’ä½œæˆ
    tab1, tab2 = st.tabs(["ğŸ“Š è§£æçµæœ", "ğŸ›  ãƒã‚¹ã‚¯ç¢ºèª (ãƒ‡ãƒãƒƒã‚°)"])

    # --- å‹•ç”»ã®èª­ã¿è¾¼ã¿æº–å‚™ ---
    cap = cv2.VideoCapture(tfile_temp.name)
    raw_fps = cap.get(cv2.CAP_PROP_FPS) or 30
    fps = raw_fps * 4 
    
    raw_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    raw_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    scale_factor = 1.0
    if raw_w > MAX_ANALYSIS_WIDTH:
        scale_factor = MAX_ANALYSIS_WIDTH / raw_w
    w = int(raw_w * scale_factor)
    h = int(raw_h * scale_factor)

    # è‰²é–¾å€¤ã®é…åˆ—åŒ–
    L_P = (np.array([p_h_min, p_s_min, p_v_min]), np.array([p_h_max, 255, 255]))
    L_G = (np.array([g_h_min, g_s_min, g_v_min]), np.array([g_h_max, 255, 255]))
    L_W = (np.array([0, 0, w_v_min]), np.array([180, w_s_max, 255]))

    # --- Tab 2: ãƒã‚¹ã‚¯ç¢ºèªãƒ¢ãƒ¼ãƒ‰ ---
    with tab2:
        st.write("å‹•ç”»ã®æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã€å„è‰²ãŒã©ã®ã‚ˆã†ã«èªè­˜ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã§ãã¾ã™ã€‚ç™½ã„éƒ¨åˆ†ãŒã€Œèªè­˜ã•ã‚Œã¦ã„ã‚‹å ´æ‰€ã€ã§ã™ã€‚")
        if st.button("ç¾åœ¨ã®è¨­å®šã§ãƒã‚¹ã‚¯ã‚’ç¢ºèª"):
            cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
            ret, frame_raw = cap.read()
            if ret:
                frame = cv2.resize(frame_raw, (w, h)) if scale_factor < 1.0 else frame_raw
                hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)

                # ãƒã‚¹ã‚¯ç”Ÿæˆ
                mask_w = cv2.inRange(hsv, L_W[0], L_W[1])
                mask_p = cv2.inRange(hsv, L_P[0], L_P[1])
                mask_g = cv2.inRange(hsv, L_G[0], L_G[1])

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.image(mask_w, caption="ãƒ›ã‚¤ãƒ¼ãƒ«èªè­˜ (ç™½ãƒã‚¹ã‚¯)", clamp=True)
                with col2:
                    st.image(mask_p, caption="ãƒ”ãƒ³ã‚¯ãƒãƒ¼ã‚«ãƒ¼èªè­˜", clamp=True)
                with col3:
                    st.image(mask_g, caption="ç·‘ãƒãƒ¼ã‚«ãƒ¼èªè­˜", clamp=True)
                
                st.image(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), caption="å…ƒã®ç”»åƒ")
            else:
                st.error("å‹•ç”»ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")

    # --- Tab 1: è§£æå®Ÿè¡Œ ---
    with tab1:
        if "df" not in st.session_state or st.session_state.get("file_id") != uploaded_file.name or st.button("å†è§£æ"):
            with st.spinner("è¨­å®šã«åŸºã¥ãè§£æä¸­..."):
                cap.set(cv2.CAP_PROP_POS_FRAMES, 0) # å…ˆé ­ã«æˆ»ã™
                data_log = []; total_angle, prev_angle = 0.0, None; last_valid_gx, last_valid_gy = np.nan, np.nan
                
                f_idx = 0
                while True:
                    ret, frame_raw = cap.read()
                    if not ret: break
                    
                    frame = cv2.resize(frame_raw, (w, h)) if scale_factor < 1.0 else frame_raw
                    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
                    
                    # 1. ãƒ›ã‚¤ãƒ¼ãƒ«é ˜åŸŸã®æ¤œå‡º
                    mask_w = cv2.inRange(hsv, L_W[0], L_W[1])
                    con_w, _ = cv2.findContours(mask_w, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    
                    wheel_roi = np.zeros((h, w), dtype=np.uint8)
                    wheel_detected = False
                    
                    if con_w:
                        # æœ€å¤§ã®ç™½é ˜åŸŸï¼ãƒ›ã‚¤ãƒ¼ãƒ«ã¨ä»®å®š
                        c_wheel = max(con_w, key=cv2.contourArea)
                        if cv2.contourArea(c_wheel) > 300: # ãƒã‚¤ã‚ºé™¤å»é–¾å€¤
                            cv2.drawContours(wheel_roi, [c_wheel], -1, 255, -1)
                            wheel_detected = True

                    gx, gy, bx, by = np.nan, np.nan, np.nan, np.nan

                    if wheel_detected:
                        # 2. ç·‘ã®æ¤œå‡º (ãƒ›ã‚¤ãƒ¼ãƒ«é ˜åŸŸå†…ã®ã¿)
                        mask_g = cv2.bitwise_and(cv2.inRange(hsv, L_G[0], L_G[1]), wheel_roi)
                        con_g, _ = cv2.findContours(mask_g, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        
                        new_gx, new_gy = np.nan, np.nan
                        if con_g:
                            c = max(con_g, key=cv2.contourArea)
                            M = cv2.moments(c)
                            if M["m00"] > 10: new_gx, new_gy = M["m10"]/M["m00"], M["m01"]/M["m00"]
                        
                        # é£›ã³å€¤å¯¾ç­–
                        if not np.isnan(last_valid_gx) and not np.isnan(new_gx):
                            if np.sqrt((new_gx - last_valid_gx)**2 + (new_gy - last_valid_gy)**2) > 100: 
                                new_gx, new_gy = last_valid_gx, last_valid_gy
                        
                        gx = new_gx if not np.isnan(new_gx) else last_valid_gx
                        gy = new_gy if not np.isnan(new_gy) else last_valid_gy
                        last_valid_gx, last_valid_gy = gx, gy

                        # 3. ãƒ”ãƒ³ã‚¯ã®æ¤œå‡º (ãƒ›ã‚¤ãƒ¼ãƒ«é ˜åŸŸå†…ã®ã¿)
                        mask_p = cv2.bitwise_and(cv2.inRange(hsv, L_P[0], L_P[1]), wheel_roi)
                        con_p, _ = cv2.findContours(mask_p, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        if con_p:
                            cp = max(con_p, key=cv2.contourArea)
                            Mp = cv2.moments(cp)
                            if Mp["m00"] > 10: bx, by = Mp["m10"]/Mp["m00"], Mp["m01"]/Mp["m00"]

                    if not np.isnan(gx) and not np.isnan(bx):
                        curr_a = np.arctan2(by - gy, bx - gx)
                        if prev_angle is not None:
                            diff = curr_a - prev_angle
                            if diff > np.pi: diff -= 2*np.pi
                            elif diff < -np.pi: diff += 2*np.pi
                            total_angle += diff
                        prev_angle = curr_a
                    
                    data_log.append({"t": f_idx/fps, "x": total_angle*RADIUS_M, "gx": gx, "gy": gy, "bx": bx, "by": by})
                    f_idx += 1
                
                cap.release()
                
                if not data_log:
                     st.error("ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                     st.stop()

                df = pd.DataFrame(data_log).interpolate().ffill().bfill()
                
                # å¹³æ»‘åŒ–å‡¦ç†
                if len(df) > 31:
                    df["x"] = savgol_filter(df["x"], 15, 2)
                    df["v"] = savgol_filter(df["x"].diff().fillna(0)*fps, 31, 2)
                    df["a"] = savgol_filter(df["v"].diff().fillna(0)*fps, 31, 2)
                    df["F"] = mass_input * df["a"]
                
                st.session_state.df = df 
                st.session_state.video_meta = {"fps": fps, "raw_fps": raw_fps, "w": w, "h": h, "path": tfile_temp.name, "scale": scale_factor}
                st.session_state.file_id = uploaded_file.name

        # --- ä»¥ä¸‹ã€ã‚°ãƒ©ãƒ•æç”»ã¨å‹•ç”»ç”ŸæˆUI ---
        if "df" in st.session_state:
            df = st.session_state.df
            
            # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ç¯„å›²è¨­å®š
            t_max_limit = float(df["t"].max())
            st.markdown("### ç¯„å›²é¸æŠ")
            c_t1, c_t2 = st.columns(2)
            t1 = c_t1.number_input(r"é–‹å§‹æ™‚åˆ» $t_1$ [s]", 0.0, t_max_limit, 0.0, 0.01)
            t2 = c_t2.number_input(r"çµ‚äº†æ™‚åˆ» $t_2$ [s]", 0.0, t_max_limit, t_max_limit, 0.01)
            
            # ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
            time_list = [round(t, 4) for t in df["t"].tolist()]
            selected_t = st.select_slider("æ™‚åˆ»ã‚’ã‚¹ã‚­ãƒ£ãƒ³ [s]", options=time_list, value=time_list[0])
            time_idx = time_list.index(selected_t); curr_row = df.iloc[time_idx]
            
            # ã‚°ãƒ©ãƒ•ã®æœ€å¤§æœ€å°å€¤
            t_m, x_m = float(df["t"].max()), float(df["x"].max())
            v_mi, v_ma = float(df["v"].min()), float(df["v"].max())
            a_mi, a_ma = float(df["a"].min()), float(df["a"].max())
            f_mi, f_ma = float(df["F"].min()), float(df["F"].max())

            marker_times = [t1, t2]

            # 4ã¤ã®ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
            r1c1, r1c2 = st.columns(2)
            with r1c1:
                st.image(create_graph_image(df.iloc[:time_idx+1], "t", "x", "t", "x", "s", "m", 'blue', 450, t_m, 0.0, x_m, markers=marker_times), channels="BGR")
                st.latex(rf"x = {curr_row['x']:.3f} \,\, \mathrm{{m}}")
            with r1c2:
                st.image(create_graph_image(df.iloc[:time_idx+1], "t", "v", "t", "v", "s", "m/s", 'red', 450, t_m, v_mi, v_ma, markers=marker_times), channels="BGR")
                st.latex(rf"v = {curr_row['v']:.3f} \,\, \mathrm{{m/s}}")

            r2c1, r2c2 = st.columns(2)
            with r2c1:
                st.image(create_graph_image(df.iloc[:time_idx+1], "t", "a", "t", "a", "s", "m/sÂ²", 'green', 450, t_m, a_mi, a_ma, markers=marker_times), channels="BGR")
                st.latex(rf"a = {curr_row['a']:.3f} \,\, \mathrm{{m/s^2}}")
            with r2c2:
                st.image(create_graph_image(df.iloc[:time_idx+1], "x", "F", "x", "F", "m", "N", 'purple', 450, x_m, f_mi, f_ma, shade_range=(t1, t2), markers=marker_times), channels="BGR")
                st.latex(rf"F = {curr_row['F']:.3f} \,\, \mathrm{{N}}")

            st.divider()
            df_w = df[(df["t"] >= t1) & (df["t"] <= t2)]
            if len(df_w) > 1:
                w_val = np.trapezoid(df_w["F"], df_w["x"]) if hasattr(np, 'trapezoid') else np.trapz(df_w["F"], df_w["x"])
                st.latex(rf"W = {format_sci_latex(w_val)} \,\, \mathrm{{J}}")

            if st.button(f"ğŸ¥ è§£æå‹•ç”»ã‚’ç”Ÿæˆã—ã¦ä¿å­˜"):
                meta = st.session_state.video_meta
                final_path = tempfile.NamedTemporaryFile(suffix='.mp4', delete=False).name
                v_size, header_h = meta["w"] // 4, (meta["w"] // 4) + 100
                font = cv2.FONT_HERSHEY_SIMPLEX
                
                graph_configs = [
                    {"xc": "t", "yc": "x", "xl": "t", "yl": "x", "xu": "s", "yu": "m", "col": "blue", "ymn": 0.0, "ymx": x_m, "xm": t_m},
                    {"xc": "t", "yc": "v", "xl": "t", "yl": "v", "xu": "s", "yu": "m/s", "col": "red", "ymn": v_mi, "ymx": v_ma, "xm": t_m},
                    {"xc": "t", "yc": "a", "xl": "t", "yl": "a", "xu": "s", "yu": "m/sÂ²", "yu_cv": "m/s^2", "col": "green", "ymn": a_mi, "ymx": a_ma, "xm": t_m},
                    {"xc": "x", "yc": "F", "xl": "x", "yl": "F", "xu": "m", "yu": "N", "col": "purple", "ymn": f_mi, "ymx": f_ma, "xm": x_m}
                ]

                out = cv2.VideoWriter(final_path, cv2.VideoWriter_fourcc(*'mp4v'), meta["raw_fps"], (meta["w"], meta["h"] + header_h))
                cap_v = cv2.VideoCapture(meta["path"])
                p_bar = st.progress(0.0)
                status_text = st.empty()
                
                for i in range(len(df)):
                    ret, frame_raw = cap_v.read()
                    if not ret: break
                    frame = cv2.resize(frame_raw, (meta["w"], meta["h"])) if meta.get("scale", 1.0) < 1.0 else frame_raw
                    canvas = np.zeros((meta["h"] + header_h, meta["w"], 3), dtype=np.uint8)
                    curr, df_s = df.iloc[i], df.iloc[:i+1]
                    
                    for idx, g in enumerate(graph_configs):
                        canvas[0:v_size, idx*v_size:(idx+1)*v_size] = create_graph_image(df_s, g["xc"], g["yc"], g["xl"], g["yl"], g["xu"], g["yu"], g["col"], v_size, g["xm"], g["ymn"], g["ymx"])
                        val_text = f"{g['yl']} = {curr[g['yc']]:>+7.3f} {g.get('yu_cv', g['yu'])}"
                        tw, _ = cv2.getTextSize(val_text, font, 0.5, 1)[0]
                        cv2.putText(canvas, val_text, (idx*v_size + (v_size-tw)//2, v_size + 50), font, 0.5, (255,255,255), 1, cv2.LINE_AA)
                    
                    cv2.putText(frame, f"t = {curr['t']:.2f} s", (20, 40), font, 1.0, (255,255,255), 2, cv2.LINE_AA)
                    if not np.isnan(curr['gx']):
                        cv2.circle(frame, (int(curr['gx']), int(curr['gy'])), 8, (0,255,0), -1)
                        cv2.circle(frame, (int(curr['gx']), int(curr['gy'])), 8, (255,255,255), 1)
                    if not np.isnan(curr['bx']):
                        cv2.circle(frame, (int(curr['bx']), int(curr['by'])), 8, (255,0,255), -1)
                        cv2.circle(frame, (int(curr['bx']), int(curr['by'])), 8, (255,255,255), 1)
                    
                    canvas[header_h:, :] = frame
                    out.write(canvas)
                    if i % 10 == 0: p_bar.progress(i / len(df)); status_text.text(f"ç”Ÿæˆä¸­: {i}/{len(df)} ãƒ•ãƒ¬ãƒ¼ãƒ ")

                cap_v.release(); out.release(); p_bar.empty(); status_text.success("âœ… å‹•ç”»ç”Ÿæˆå®Œäº†")
                with open(final_path, "rb") as f: st.download_button("ğŸ’¾ å‹•ç”»ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", f, file_name=f"analysis_v{VERSION}.mp4")
